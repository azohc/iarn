{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook estudiaremos cómo crear y visualizar árboles de decisión en scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fijar generador de números aleatorios para obtener siempre los mismos resultados\n",
    "np.random.seed(28)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "# Cargamos el dataset del iris\n",
    "iris = load_iris()\n",
    "iris.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un árbol de decisión con la configuración por defecto y lo entrenamos\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si no está instalda la biblioteca graphviz\n",
    "\n",
    "# exportar al fichero tree.dot\n",
    "# se puede convertir a png con el siguiente comando en la consola:\n",
    "# dot -Tpng tree.dot -o tree.png\n",
    "export_graphviz(clf, out_file='tree.dot',\n",
    "               feature_names=iris.feature_names,\n",
    "               class_names=iris.target_names,\n",
    "               filled=True, rounded=True,\n",
    "               special_characters=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-67a0d91523fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Si está instalda la biblioteca graphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Vamos a mostrar el árbol de decisión generado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m dot_data = export_graphviz(clf, out_file=None, \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "# Si está instalda la biblioteca graphviz\n",
    "import graphviz\n",
    "\n",
    "# Vamos a mostrar el árbol de decisión generado\n",
    "dot_data = export_graphviz(clf, out_file=None, \n",
    "                     feature_names=iris.feature_names,  \n",
    "                     class_names=iris.target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9777777777777777)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Partimos el conjunto de datos en entrenamiento (70%) y prueba (30%)\n",
    "# random_state es la semilla del generador de números aleatorios. Normalmente no se establece pero\n",
    "# nosotros lo usamos para obtener siempre el mismo resultado.\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=0)\n",
    "\n",
    "# Creamos y entrenamos el árbol de decisión\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculamos la precisión del modelo de entrenamiento y de test\n",
    "train_accuracy = clf.score(X_train, y_train)\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9809523809523809, 0.9777777777777777)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repetimos el proceso pero modificando los parámetros de aprendizaje del árbol\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\",  # por defecto Gini pero podemos cambiar a entropía\n",
    "                             max_depth=4,          # profundidad máxima del árbol\n",
    "                             min_samples_split=5,  # mínimo de muestras en el nodo para seguir dividiéndolo\n",
    "                             random_state=0)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculamos la precisión del modelo de entrenamiento y de test\n",
    "train_accuracy = clf.score(X_train, y_train)\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso tenemos un arbol que está menos sobre-ajustado que el anterior porque obtiene igual resultado en test y más bajo en entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curva de aprendizaje según un parámetro del clasificador "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitar la profundidad máxima del árbol de decisión puede servir para obtener un clasificador menos \"ajustado\" a los datos de entrenamiento y, por tanto, que generalice mejor en datos nuevos.\n",
    "Podemos calcular la profundidad optima usando validación cruzada y probando distintos valores de ese parámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "max_depths = range(1, 6)\n",
    "for md in max_depths: \n",
    "    # Entrenar y validar\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=md, min_samples_split=2)\n",
    "    scores = cross_validate(clf, iris.data, iris.target, scoring='accuracy', cv=10, return_train_score=True)\n",
    "    \n",
    "    train_accuracy.append(np.mean(scores['train_score']))\n",
    "    test_accuracy.append(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(max_depths, train_accuracy, color=\"r\",  label=\"Training\")\n",
    "plt.plot(max_depths, test_accuracy, color=\"g\", label=\"Test\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Curva de aprendizaje\")\n",
    "plt.xlabel(\"Parametro\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para max_depth=3 obtenemos el mejor valor de exactitud para el conjunto de prueba. A partir de esa profundidad la métrica mejora para el conjunto de entrenamiento y empeora para el conjunto de prueba indicando que el clasificador está sobre-entrenado y generaliza peor.\n",
    "\n",
    "Podríamos hacer lo mismo con el resto de parámetros del árbol hasta encontrar lo que funcionan mejor para nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenando el clasificador final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Una vez hemos determinado la combinación de parámetros del clasificador mejores (evitando sobre-aprender) y tenemos claro cuál es el rendimiento esperable de dichos parámetros cuando usamos datos nuevos (su rendimiento en la parte de test), podemos volver a entrenar el modelo con todo el conjunto de datos y los parámetros elegidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponemos la siguiente combinación como la mejor (probablemente no es cierto)\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", \n",
    "                             splitter=\"best\",\n",
    "                             max_depth=3,\n",
    "                             min_samples_split=2, \n",
    "                             max_leaf_nodes=None)\n",
    "clf = clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si no está instalda la biblioteca graphviz\n",
    "\n",
    "# exportar al fichero tree.dot\n",
    "# se puede convertir a png con el siguiente comando en la consola:\n",
    "# dot -Tpng tree.dot -o tree.png\n",
    "export_graphviz(clf, out_file='tree.dot', \n",
    "                     feature_names=iris.feature_names,  \n",
    "                     class_names=iris.target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graphviz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a821721a90bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                      \u001b[0mfilled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                      special_characters=True)  \n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'graphviz' is not defined"
     ]
    }
   ],
   "source": [
    "# Si está instalda la biblioteca graphviz\n",
    "\n",
    "# Este sería el árbol de clasificación que usaríamos ante datos nuevos, \n",
    "# y que, consideramos que ha aprendido razonablemente bien de los datos disponibles\n",
    "dot_data = export_graphviz(clf, out_file=None, \n",
    "                     feature_names=iris.feature_names,  \n",
    "                     class_names=iris.target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos el valor de un ejemplo que nunca hemos visto\n",
    "clf.predict([[5, 3, 1, 0.1]])\n",
    "# Nos da la clase 0 que es setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
